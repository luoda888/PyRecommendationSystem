{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "from utils.utils import SparseFeat, DenseFeat, VarLenSparseFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_layers(feature_columns):\n",
    "    # 构建Input层字典，并以dense和sparse两类字典的形式返回\n",
    "    \n",
    "    dense_input_dict, sparse_input_dict = {}, {}\n",
    "    \n",
    "    for feat in feature_columns:\n",
    "        if isinstance(feat, SparseFeat):\n",
    "            sparse_input_dict[feat.name] = Input(shape=(1,), name=feat.name)\n",
    "        else:\n",
    "            dense_input_dict[feat.name] = Input(shape=(feat.dimension,), name=feat.name)\n",
    "    \n",
    "    return dense_input_dict, sparse_input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_layers(feature_columns, input_layers_dict, is_linear, prefix=''):\n",
    "    # 定义一个embedding层对应的字典\n",
    "    embedding_layers_dict = {}\n",
    "    \n",
    "    # 将特征中的sparse特征筛选出来\n",
    "    sparse_feature_columns = list(filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []\n",
    "    \n",
    "    # 如果是线性部分的embedding层，其维度是1， 否则维度是自己定义的embedding维度\n",
    "    if is_linear:\n",
    "        for feat in sparse_feature_columns:\n",
    "            embedding_layers_dict[feat.name] = Embedding(feat.vocab_size+1, 1, name=prefix + '1d_emb_' + feat.name)\n",
    "    else:\n",
    "        for feat in sparse_feature_columns:\n",
    "            embedding_layers_dict[feat.name] = Embedding(feat.vocab_size+1, feat.embed_dim, name=prefix + 'kd_emb_' + feat.name)\n",
    "    return embedding_layers_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dnn_out(dnn_inputs, units=(32, 16)):\n",
    "    dnn_out = dnn_inputs\n",
    "    for out_dim in units:\n",
    "        dnn_out = Dense(out_dim)(dnn_out)\n",
    "    return dnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCF(dnn_feature_columns):\n",
    "    # 构建输入层，即所有特征对应的Input()层，这里使用字典的形式返回， 方便后续构建模型\n",
    "    _, sparse_input_dict = build_input_layers(dnn_feature_columns)  # 没有dense特征\n",
    "    \n",
    "    # 构建模型的输入层，模型的输入层不能是字典的形式，应该将字典的形式转换成列表的形式\n",
    "    # 注意： 这里实际的输入与Input（）层的对应，是通过模型的输入时候的字典数据的key与对应name的Input层\n",
    "    input_layers = list(sparse_input_dict.values())\n",
    "    \n",
    "    # 创建两份embedding向量，由于embedding层的name不能相同，所以这里加入一个prefix参数\n",
    "    GML_embedding_dict = build_embedding_layers(dnn_feature_columns, sparse_input_dict, is_linear=False, prefix='GML')\n",
    "    MLP_embedding_dict = build_embedding_layers(dnn_feature_columns, sparse_input_dict, is_linear=False, prefix='MLP')\n",
    "    print(GML_embedding_dict)\n",
    "    \n",
    "    # 构建GML的输出\n",
    "    GML_user_emb = Flatten()(GML_embedding_dict['user_id'](sparse_input_dict['user_id']))   # B X embed_dim\n",
    "    print(GML_user_emb)\n",
    "    GML_item_emb = Flatten()(GML_embedding_dict['movie_id'](sparse_input_dict['movie_id'])) # B X embed_dim\n",
    "    GML_out = tf.multiply(GML_user_emb, GML_item_emb) # 按照元素相乘\n",
    "    \n",
    "    # 构建MLP的输出\n",
    "    MLP_user_emb = Flatten()(MLP_embedding_dict['user_id'](sparse_input_dict['user_id']))  # B X embed_dim\n",
    "    MLP_item_emb = Flatten()(MLP_embedding_dict['movie_id'](sparse_input_dict['movie_id']))  # B X embed_dim\n",
    "    MLP_dnn_input = Concatenate(axis=1)([MLP_user_emb, MLP_item_emb])\n",
    "    MLP_dnn_out = get_dnn_out(MLP_dnn_input, (32, 16))\n",
    "    \n",
    "    # 将dense特征和Sparse特征拼接在一起\n",
    "    concat_dnn = Concatenate(axis=1)(GML_out, MLP_dnn_out)\n",
    "    \n",
    "    # 输入到dnn中，需要提前定义需要几个残差块\n",
    "    # output_layer = Dense(1, 'sigmoid')(concat_out)\n",
    "    output_layer = Dense(1)(concat_out)\n",
    "    \n",
    "    model = Model(input_layers, output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据，NCF使用的特征只有user_id和item_id\n",
    "rnames = ['user_id','movie_id','rating','timestamp']\n",
    "data= pd.read_csv('./data/ml-1m/ratings.dat', sep=\"::\", engine='python', names=rnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbe = LabelEncoder()\n",
    "data['user_id'] = lbe.fit_transform(data['user_id'])\n",
    "data['movie_id'] = lbe.fit_transform(data['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[['user_id', 'movie_id']]\n",
    "train_data['label'] = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3177</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  label\n",
       "0        0      1104      5\n",
       "1        0       639      3\n",
       "2        0       853      3\n",
       "3        0      3177      4\n",
       "4        0      2162      5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = [\n",
    "    SparseFeat('user_id', train_data['user_id'].nunique(), 8),\n",
    "    SparseFeat('movie_id', train_data['movie_id'].nunique(), 8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor 'user_id:0' shape=(None, 1) dtype=float32>, 'movie_id': <tf.Tensor 'movie_id:0' shape=(None, 1) dtype=float32>}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'item_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-828a08b744d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 构建FM模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNCF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdnn_feature_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-b96cd968891b>\u001b[0m in \u001b[0;36mNCF\u001b[1;34m(dnn_feature_columns)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 构建MLP的输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mMLP_user_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP_embedding_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_input_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# B X embed_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mMLP_item_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP_embedding_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_input_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# B X embed_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mMLP_dnn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMLP_user_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMLP_item_emb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mMLP_dnn_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dnn_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLP_dnn_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'item_id'"
     ]
    }
   ],
   "source": [
    "# 构建FM模型\n",
    "history = NCF(dnn_feature_columns)\n",
    "history.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
